name: "example_pipeline_with_filter"

stages:
  # Stage 1: Read from Hugging Face dataset, calculate metrics, and filter
  - name: "score_and_filter"
    input:
      source:
        type: "huggingface"
        path: "imdb"
        streaming: false
    operators:
      # Filter based on metrics
      - id: "textstat_filter"
        kind: "filter"
        op: "textstat-filter"
        params:
          column: "text"
          min_scores:
            flesch_reading_ease: 0
            automated_readability_index: 0
            aggregate_reading_level: 0
            syllable_count: 32.0
            lexicon_count: 23.0
            sentence_count: 1.0
            character_count: 118.0
            letter_count: 109.0
            polysyllable_count: 0.0
            monosyllable_count: 13.0
            difficult_words: 4.0
          max_scores:
            flesch_reading_ease: 100
            automated_readability_index: 100
            aggregate_reading_level: 100
            syllable_count: 2331.9
            lexicon_count: 1554.0
            sentence_count: 89.1
            character_count: 7466.3
            letter_count: 7193.0
            polysyllable_count: 216.4
            monosyllable_count: 1044.1
            difficult_words: 213.4
          metrics:
            - flesch_reading_ease
            - automated_readability_index
            - aggregate_reading_level
            - syllable_count
            - lexicon_count
            - sentence_count
            - character_count
            - letter_count
            - polysyllable_count
            - monosyllable_count
            - difficult_words
    output:
      source:
        type: "parquet"
        path: "./example_data/filtered_output"
